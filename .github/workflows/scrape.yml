name: Scrape EFDA Imports

on:
  schedule:
    # Daily at 6 AM UTC (9 AM EAT)
    - cron: "0 6 * * *"
  workflow_dispatch:

concurrency:
  group: scrape-pipeline
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 240

    env:
      EFDA_USERNAME: ${{ secrets.EFDA_USERNAME }}
      EFDA_PASSWORD: ${{ secrets.EFDA_PASSWORD }}
      TURSO_AUTH_TOKEN: ${{ secrets.TURSO_AUTH_TOKEN }}
      TURSO_DATABASE_URL: ${{ secrets.TURSO_DATABASE_URL }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install Python dependencies
        run: pip install -r requirements.txt

      - name: Cache Playwright browsers
        id: playwright-cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ hashFiles('requirements.txt') }}

      - name: Install Playwright Chromium
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: python -m playwright install chromium --with-deps

      - name: Install Playwright system deps
        if: steps.playwright-cache.outputs.cache-hit == 'true'
        run: python -m playwright install-deps chromium

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm
          cache-dependency-path: dashboard/package-lock.json

      - name: Install Node dependencies
        run: cd dashboard && npm ci

      - name: Restore database cache
        uses: actions/cache/restore@v4
        id: db-cache
        with:
          path: |
            data/efda.sqlite3
            data/state/last_sync.json
          key: scrape-db-${{ github.run_id }}
          restore-keys: scrape-db-

      - name: Run scraper pipeline
        run: bash scripts/run_pipeline.sh

      - name: Delete previous database cache
        if: always()
        continue-on-error: true
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          gh cache list --key scrape-db- --json id,key -q '.[].key' | while read key; do
            gh cache delete "$key" || true
          done

      - name: Save database cache
        uses: actions/cache/save@v4
        if: always()
        with:
          path: |
            data/efda.sqlite3
            data/state/last_sync.json
          key: scrape-db-${{ github.run_id }}
